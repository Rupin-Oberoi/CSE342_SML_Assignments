# -*- coding: utf-8 -*-
"""A2_Rupin_2020571.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lM7fQE6cI7mrHhv-Z0EnySa8tADRQvtB
"""

import numpy as np
import matplotlib.pyplot as plt
from numpy import linalg as la
import math

#Q1

"""Generating 100 samples for class 1"""

m1c1, m2c1 = 0.5, 0.8
if np.random.rand()<m1c1:
  e1 = 1
else:
  e1 = 0
if np.random.rand()<m1c1:
  e2 = 1
else:
  e2 = 0
arr1 = np.array([[e1,e2]])
for i in range (1,100):
  if np.random.rand()<m1c1:
    arr1 = np.append(arr1,[[1,0]], axis=0)
  else:
    arr1= np.append(arr1,[[0,0]], axis=0)
  if np.random.rand()<m2c1:
    arr1[i,1] = 1
  else:
    arr1[i,1] = 0

"""Generating 100 samples for class 2"""

m1c2, m2c2 = 0.9, 0.2
if np.random.rand()<m1c2:
  e1 = 1
else:
  e1 = 0
if np.random.rand()<m1c2:
  e2 = 1
else:
  e2 = 0
arr2 = np.array([[e1,e2]])
for i in range (1,100):
  if np.random.rand()<m1c2:
    arr2 = np.append(arr2,[[1,0]], axis=0)
  else:
    arr2= np.append(arr2,[[0,0]], axis=0)
  if np.random.rand()<m2c2:
    arr2[i,1] = 1
  else:
    arr2[i,1] = 0

"""Dividing into training and test sets"""

training1 = np.array(arr1[0:50])
training2 = np.array(arr2[0:50])
test1 = np.array(arr1[50:100])
test2 = np.array(arr2[50:100])
test = np.append(test1, test2, axis=0)

"""MLE Estimates for Î¼1 for n=1 to 50"""

mle1 = np.array([[training1[0][0], training1[0][1]]])
for i in range(1,50):
  sum1, sum2 = 0,0
  for j in range (0,i+1):
    sum1 += training1[j][0]
    sum2 += training1[j][1]
  mle1 = np.append(mle1, [[sum1/(i+1), sum2/(i+1)]], axis =0)
mle11, mle21 = mle1[49][0], mle1[49][1]

xaxis = range(1,51,1)
yaxis = [mle1[x-1][0]/m1c1 for x in xaxis]
y1 = [1 for x in xaxis];
plt.plot(xaxis, yaxis)
plt.plot(xaxis, y1, linestyle = 'dashed')
min, max = plt.ylim()
plt.ylim(-0.1,3)
plt.xlabel('n')
plt.ylabel('mle/mu1')
plt.show()

xaxis = range(1,51,1)
yaxis = [mle1[x-1][1]/m2c1 for x in xaxis]
y1 = [1 for x in xaxis];
plt.plot(xaxis, yaxis)
plt.plot(xaxis, y1, linestyle = 'dashed')
min, max = plt.ylim()
plt.ylim(-0.1,3)
plt.xlabel('n')
plt.ylabel('mle/mu2')
plt.show()

mle2 = np.array([[training2[0][0], training2[0][1]]])
for i in range(1,50):
  sum1, sum2 = 0,0
  for j in range (0,i+1):
    sum1 += training2[j][0]
    sum2 += training2[j][1]
  mle2 = np.append(mle2, [[sum1/(i+1), sum2/(i+1)]], axis =0)
mle12, mle22 = mle2[49][0], mle2[49][1]

xaxis = range(1,51,1)
yaxis = [mle2[x-1][0]/m1c2 for x in xaxis]
y1 = [1 for x in xaxis];
plt.plot(xaxis, yaxis)
plt.plot(xaxis, y1, linestyle = 'dashed')
min, max = plt.ylim()
plt.ylim(-0.5,3)
plt.show()

xaxis = range(1,51,1)
yaxis = [mle2[x-1][1]/m2c2 for x in xaxis]
y1 = [1 for x in xaxis];
plt.plot(xaxis, yaxis)
plt.plot(xaxis, y1, linestyle = 'dashed')
min, max = plt.ylim()
plt.ylim(-0.5,3)
plt.show()

"""Scatter plot for training set of class 1"""

scatter_x1 = [training1[i,0] for i in range(0,50,1)]
scatter_y1 = [training1[i,1] for i in range(0,50,1)]
plt.scatter(scatter_x1, scatter_y1)
plt.show()

scatter_x2 = [training2[i,0] for i in range(0,50,1)]
scatter_y2 = [training2[i,1] for i in range(0,50,1)]
plt.scatter(scatter_x2, scatter_y2)
plt.show()

"""testing"""

correct_class1 = 0
for i in test1:
  if math.log((mle11**i[0])*((1-mle11)**(1-i[0]))*(mle21**i[1])*((1-mle21)**(1-i[1])))>math.log((mle12**i[0])*((1-mle12)**(1-i[0]))*(mle22**i[1])*((1-mle22)**(1-i[1]))):
    correct_class1+=1
print("Number of class 1 samples correctly classified: "+ str(correct_class1))

correct_class2 = 0
for i in test2:
  if math.log((mle11**i[0])*((1-mle11)**(1-i[0]))*(mle21**i[1])*((1-mle21)**(1-i[1])))<math.log((mle12**i[0])*((1-mle12)**(1-i[0]))*(mle22**i[1])*((1-mle22)**(1-i[1]))):
    correct_class2+=1
print("Number of class 2 samples correctly classified: "+ str(correct_class2))

#Q2
"""sml_a2q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YvlVRJBHUFHFtyCcSe7jfbuVN5edzACK
"""


x = [[4,7], [2,3]]
mu = []
for i in range(0,len(x)):
  sum = 0
  for j in range(0, len(x[0])):
    sum+=x[i][j]
  mu = np.append(mu, sum/len(x[0]))
xc = []
for i in range(0, len(x)):
  diff = []
  for j in range(0, len(x[0])):
    diff = np.append(diff, x[i][j]- mu[i])
  xc = np.append(xc, diff, axis=0)
xc = np.reshape(xc,(len(x), len(x[0])))
mu = np.reshape(mu,(2,1))
covxc = np.cov(xc)
w,v = la.eig(covxc)
f = w.argsort()[::-1]   
w = w[f]
v = v[:,f]
u=v
print("U =")
print(u)
u_trans = np.transpose(u)

y = np.matmul(u_trans, xc)
print("Y =")
print(y)
uy = np.matmul(u, y)
uypmu = np.add(uy, mu)
sq = 0
for i in range(0, len(x)):
  for j in range(0, len(x[0])):
    sq+=(x[i][j] - uypmu[i][j])**2
mse = sq/(len(x)*len(x[0]))
print("mse="+str(mse))

covx1 = [[1,0,0,0,0], [0,3,0,0,0], [0,0,4,0,0], [0,0,0,9,0], [0,0,0,0,4]]
mu1 = [2,3,4,4,1]
x1 = np.random.multivariate_normal(mu1, covx1, 6)
x1 = np.transpose(x1)
mu1 = []
d, n = len(x1), len(x1[0])
for i in range(0,d):
  sum = 0
  for j in range(0, n):
    sum+=x1[i][j]
  mu1 = np.append(mu1, sum/n)
xc1 = []
for i in range(0, d):
  diff = []
  for j in range(0, n):
    diff = np.append(diff, x1[i][j]- mu1[i])
  xc1 = np.append(xc1, diff, axis=0)
xc1 = np.reshape(xc1,(len(x1), len(x1[0])))
mu1 = np.reshape(mu1,(len(mu1), 1))
covxc1 = np.cov(xc1)
w,v = la.eig(covxc1)
fa = w.argsort()[::-1]   
w = w[fa]
v = v[:,fa]
u1=v
print("U = ")
print(u1)

u1_trans = np.transpose(u1)
y1 = np.matmul(u1_trans, xc1)
u1y1 = np.matmul(u1, y1)
u1y1pmu1 = np.add(u1y1, mu1)
sq = 0
for i in range(0, len(x1)):
  for j in range(0, len(x1[0])):
    sq+=(x1[i][j] - u1y1pmu1[i][j])**2
mse = sq/(len(x1)*len(x1[0]))
print("MSE = "+ str(mse))

mse_arr = []
for p in range(1, len(u1)+1):
  fp = w.argsort()[-p:][::-1]
  up = v[:,fp]
  up_trans = np.transpose(up)
  yp = np.matmul(up_trans, xc1)
  upyp = np.matmul(up, yp)
  upyppmu1 = np.add(upyp, mu1)
  sq = 0
  for i in range(0, len(x1)):
    for j in range(0, len(x1[0])):
      sq+=(x1[i][j] - upyppmu1[i][j])**2
  mse = sq/(len(x1)*len(x1[0]))
  mse_arr = np.append(mse_arr, mse)
x_axis = np.arange(1,len(u1)+1)
plt.plot(x_axis, mse_arr)
plt.show()